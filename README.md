# Stock Price Prediction

## A Production-Ready Machine Learning Pipeline for Next Day Closing Prices Forecasting

This repository contains a complete machine learning pipeline for predicting next-day stock closing prices using `ARIMA`, `XGBoost`, and `LSTM models`. The project includes **data preprocessing**, **end-to-end modeling**, **hyperparameter optimization**, and **deployment-ready artifacts**.

**Primary Goal:** Build a robust, interpretable, and high-performance regression model suitable for real-world deployment in stock price analyzing and prediction.

**Status:** Trained, evaluated, and validated  
**Output:** model file ready for integration 

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
    - [Key Engineering Decisions](#key-engineering-decisions)
- [Dataset & Features](#dataset-features)
- [Modeling Pipeline](#modeling-pipeline)
- [Model Selection](#model-selection)
    - [Modeling Process](#modeling-process)
    - [Overall Model Review](#overall-model-review)
    - [Best Performing Model](#best-performing-model)
    - [Final Recommendation](#final-recommendation)
- [File Structure](#file-structure)
- [Dependencies](#dependencies)
- [Installation](#installation)
    - [Clone the Repository](#clone-the-repository)
    - [Create a virtual environment](#create-a-virtual-environment)
    - [Install Dependencies](#install-dependencies)
- [Model Inference](#model-inference)
- [Future Improvements](#future-improvements)
- [Contributing](#contributing)
- [Contact](#contact)
- [License](#license)

---

## Overview

This repository contains a complete end-to-end project for forecasting the next-day closing price of Apple Inc. (AAPL) stock using historical daily data from 2012 to 2024. Three advanced models â€” **ARIMA**, **XGBoost**, and **LSTM** â€” were rigorously evaluated. The **LSTM model** was selected as the final production-ready solution due to its superior accuracy and generalization capability.

The code is organized into modular directories for data, source code, visualizations, and artifacts, ensuring maintainability and reproducibility.

### Key Engineering Decisions

- **Time-Based Splits**: Strict chronological splitting (Train: 2012â€“2021, Val: 2022, Test: 2023â€“2024) to prevent data leakage and simulate real-world forecasting.
- **Model-Specific Optimization**: Used `auto_arima` for ARIMA, `Optuna` for XGBoost, and manual tuning for LSTM to ensure fair, state-of-the-art hyperparameter optimization.
- **Native Serialization**: Saved models in their optimal formats (`.keras` for LSTM, `.pkl` for others) for reliability and performance.
- **Comprehensive Evaluation**: Employed multiple metrics (RMSE, MAE, MAPE, RÂ²) and time-series cross-validation to assess both performance and robustness.

---

## Dataset & Features

- **Source**: Historical stock data for **AAPL** (Apple Inc.) downloaded via `yfinance`.
- **Time Range**: January 1, 2012 â€“ December 31, 2024.
- **Target Variable**: Daily closing price (`Close`).
- **Features**: The primary model (LSTM) uses a **univariate time series** of the last 10 closing prices to predict the next day's price. This simple, interpretable feature set avoids look-ahead bias and ensures real-time applicability.

---

## Modeling Pipeline

The end-to-end pipeline consists of the following stages:

1. **Data Acquisition**: Fetch raw OHLCV data from `yfinance`.
2. **Preprocessing**: Clean data, handle missing values (forward-fill weekends), and create a univariate `Close` price series.
3. **Time-Based Splitting**: Partition data into training, validation, and test sets without shuffling.
4. **Model Training & Optimization**:
   - **ARIMA**: Automatic order selection using `pmdarima`.
   - **XGBoost**: Hyperparameter tuning with `Optuna` using lagged features.
   - **LSTM**: Architecture tuning (units, dropout, learning rate) on raw price sequences.
5. **Evaluation**: Compute metrics on both validation and test sets. Perform time-series cross-validation on the training set.
6. **Model Selection**: Choose the best model based on test set performance and overfitting analysis.
7. **Persistence**: Save the final model and its artifacts (e.g., scaler) to the `artifacts/` directory.

---

## Model Selection

### Modeling Process

This project implemented and evaluated three state-of-the-art forecasting modelsâ€”**ARIMA (auto_arima)**, **XGBoost (Optuna)**, and **LSTM (Manual Tuning)**â€”to predict the next-day closing price of stock using historical daily price data from 2012 to 2024. Each model underwent a rigorous, multi-stage evaluation process. Performance was meticulously assessed on both training and test sets using key regression metrics: **RMSE, MAE, MAPE, MSE, and RÂ²**. Time-series cross-validation was used to gauge model robustness, and a comprehensive overfitting analysis compared cross-validated and test performance to ensure generalization.

---

### Overall Model Review

Among all evaluated models, **LSTM** emerged as the superior performer, demonstrating an exceptional combination of **high accuracy, strong generalization, and robustness** on unseen future data.

- **LSTM delivers outstanding test performance** with the lowest Test RMSE (8.71), Test MAE (7.595), and Test MAPE (1.117%), indicating highly precise price predictions. Its Test RÂ² score of **0.919** confirms it explains 91% of the variance in the test set, a remarkable achievement for stock forecasting.
- **LSTM exhibits exceptional generalization**. The overfitting ratio, significantly lower than other models, indicates that the model's performance on unseen data is *better* than its cross-validated performance on historical data, suggesting it has learned robust temporal patterns rather than overfitting to noise.
- **ARIMA**, while showing a low test RMSE (31.828), suffers from a catastrophically negative RÂ² score (-0.071) and a very high CV MAPE (12.54%), indicating poor explanatory power and instability.
- **XGBoost**, despite strong cross-validation results (CV RMSE: 10.055), shows clear signs of overfitting with an Overfitting Ratio of 5.913. Its test performance (RMSE: 59.453) is significantly worse than its training performance, making it unreliable for future predictions.

Therefore, **LSTM (Manual Tuning)** is selected as the final, production-ready model for the Advanced Stock Price Forecasting System.

---

### Best Performing Model

Based on a holistic evaluation prioritizing **test set accuracy, generalization ability (low overfitting ratio), and explanatory power (RÂ²)**, LSTM (Manual Tuning) is the definitive best model:

- **Cross-Validation RMSE:** `0.086`
- **Test RMSE:** `8.71`
- **Test MAE:** `7.595`
- **Test MAPE:** `4.117%`
- **Test RÂ²:** `0.919`
- **Model Status:** `Good`

---

### Final Recommendation

Based on its unparalleled accuracy, robust generalization, and practical utility, the **LSTM** model is strongly recommended for production deployment in the Advanced Stock Price Forecasting System.

The model, along with its associated scaler and configuration, has been successfully persisted for immediate use in a prediction pipeline. Future enhancements could include:
- Incorporating additional features (e.g., trading volume, technical indicators, macroeconomic data) to potentially improve accuracy further.
- Implementing a rolling retraining strategy to keep the model updated with the latest market data.
- Developing a confidence interval or prediction interval around the point forecast to quantify uncertainty.
- Exploring more advanced architectures like Transformer models or hybrid CNN-LSTM models for even more complex pattern recognition.

---

## File Structure

The project is organized into logical directories for clarity and scalability.
```bash
Stock-Price-Forecasting/
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ model-performance/
â”‚   â”‚   â”œâ”€â”€ a_ModelPerformance.csv
â”‚   â”‚   â”œâ”€â”€ a_overfittingAnalysis.csv
â”‚   â”‚   â”œâ”€â”€ arimaPerformance.csv
â”‚   â”‚   â”œâ”€â”€ lstmPerformance.csv
â”‚   â”‚   â””â”€â”€ xgboostPerformance.csv
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ model_Arima.pkl
â”‚   â”‚   â”œâ”€â”€ model_LSTM.keras
â”‚   â”‚   â””â”€â”€ model_XGBoost.keras
â”‚   â””â”€â”€ report.md
â”œâ”€â”€ data/
â”‚   â””â”€â”€ AAPL_preprocessed.csv
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ DataPreprocessing.ipynb
â”‚   â”œâ”€â”€ model_Arima.ipynb
â”‚   â”œâ”€â”€ model_LSTM.ipynb
â”‚   â”œâ”€â”€ model_XGBoost.ipynb
â”‚   â””â”€â”€ ModelSelection.ipynb
â”œâ”€â”€ src/
â”‚    â”œâ”€â”€ utilities.py
â”œâ”€â”€ visualizations/
â”‚    â”œâ”€â”€ ActualvsPredicted.png
â”‚    â”œâ”€â”€ ClosingPriceAnalysis.png
â”‚    â”œâ”€â”€ DailyReturnAnalysis.png
â”‚    â”œâ”€â”€ ModelPerformance.png
â”‚    â”œâ”€â”€ MovingAverages.png
â”‚    â”œâ”€â”€ OverfittingAnalysis.png
â”‚    â”œâ”€â”€ OverfittingIndicator.png
â”‚    â””â”€â”€ VolumeofSalesAnalysis.png
â”œâ”€â”€ .gitignore
â”œâ”€â”€ app.py
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ runtime.txt

```

---

## Dependencies

The project requires the following key Python libraries:

```python
# Core Python libraries
numpy==1.26.4
Cython==3.1.4
pandas==2.3.2
yfinance==0.2.66
matplotlib==3.10.6
seaborn==0.13.2
joblib==1.5.2

# Scikit-learn utilities
scikit-learn==1.7.2
scikeras==0.13.0

# Machine Learning & Optimization
xgboost==3.0.5
optuna==4.5.0

# ARIMA models for time series forecasting
statsmodels==0.14.5
pmdarima==2.0.3

# Deep Learning with TensorFlow
tensorflow==2.16.1

# Building web apps with Streamlit
streamlit==1.50.0
```

---

## Installation

### Clone the Repository

```bash
git clone https://github.com/tshihab07/Stock-Price-Forecasting.git
```

```bash
cd Stock-Price-Forecasting
```

### Create a virtual environment

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.\.venv\Scripts\activate   # Windows
```

### Install Dependencies

```python
pip install -r requirements.txt
```

---

## Model Inference
```python
streamlit run app.py
```

---

## Future Improvements

- Incorporate additional features (e.g., trading volume, technical indicators like RSI or MACD).
- Implement a rolling retraining strategy to adapt to evolving market conditions.
- Develop prediction intervals to quantify forecast uncertainty.
- Experiment with more advanced architectures (e.g., Transformers, Temporal Fusion Transformers).
- Add real-time data ingestion for live forecasting.

---

## Contributing

Contributions are welcome! Please feel free to submit a pull request.
- Fork the project.
- Create your feature branch
- Commit changes
- Push
- Open a Pull Request

---

## Contact

E-mail: tushar.shihab13@gmail.com <br>
More Projects: ğŸ‘‰ğŸ¿ [Projects](https://github.com/tshihab07?tab=repositories)<br>
LinkedIn: [Tushar Shihab](https://www.linkedin.com/in/tshihab07/)

---


## License

This project is licensed under the [MIT License](LICENSE).