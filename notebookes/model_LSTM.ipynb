{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c504bfb5",
   "metadata": {},
   "source": [
    "# LSTM Model Development With Adam Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b689436",
   "metadata": {},
   "source": [
    "# Import Libraries and Root Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bfc384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Configure the utilities module path for imports \"\"\"\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# get project root as parent of current working directory\n",
    "project_root = Path(os.getcwd()).parent\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e783e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Import libraries to develop XGBoost model \"\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from src.utilities import StockDataProcessor, Evaluator, ModelPersister"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d9f225",
   "metadata": {},
   "source": [
    "# Feature and Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d29459",
   "metadata": {},
   "source": [
    "## Artifacts Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15099997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset from file\n",
    "file = Path(r'../data/AAPL_preprocessed.csv')\n",
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce17977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, validation, and test sets\n",
    "train, test = StockDataProcessor.time_based_split(data)\n",
    "\n",
    "# feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "y_scaled = scaler.fit_transform(data[['Close']])\n",
    "\n",
    "SEQ_LEN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82b9ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale train and test data\n",
    "train_scale = y_scaled[:len(train)]\n",
    "test_scale = y_scaled[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae570fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sequences\n",
    "processor = StockDataProcessor()\n",
    "\n",
    "x_train, y_train = processor.create_sequences(train_scale, seq_length=SEQ_LEN)\n",
    "x_test, y_test = processor.create_sequences(test_scale, seq_length=SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d239076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape sequences for LSTM input\n",
    "x_train = x_train.reshape((x_train.shape[0], SEQ_LEN, 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], SEQ_LEN, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66d146e",
   "metadata": {},
   "source": [
    "# Model Training with Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24df55dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define different LSTM hyperparameter configurations for experimentation.\n",
    "lstm_configs = [\n",
    "    {'units': 50, 'dropout': 0.2, 'lr': 0.001},\n",
    "    {'units': 100, 'dropout': 0.3, 'lr': 0.001},\n",
    "    {'units': 50, 'dropout': 0.2, 'lr': 0.0005},\n",
    "    {'units': 100, 'dropout': 0.3, 'lr': 0.0005}\n",
    "]\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_config = None\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0813242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through each  LSTM configuration to train and evaluation models\n",
    "for config in lstm_configs:\n",
    "    model = Sequential([\n",
    "        LSTM(config['units'], return_sequences=True, input_shape=(SEQ_LEN, 1)),\n",
    "        Dropout(config['dropout']),\n",
    "        LSTM(config['units'], return_sequences=False),\n",
    "        Dropout(config['dropout']),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=config['lr']), loss='mse')\n",
    "    history = model.fit(x_train, y_train, validation_data=(x_test, y_test),\n",
    "                        epochs=50, batch_size=32, callbacks=[EarlyStopping(patience=10)], verbose=0)\n",
    "    \n",
    "    if min(history.history['val_loss']) < best_val_loss:\n",
    "        best_val_loss = min(history.history['val_loss'])\n",
    "        best_config = config\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353d4d85",
   "metadata": {},
   "source": [
    "## Apply Model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf76bf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    }
   ],
   "source": [
    "model = best_model\n",
    "\n",
    "# train set prediction\n",
    "train_pred_scaled = model.predict(x_train).flatten()\n",
    "train_pred = scaler.inverse_transform(train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# test set prediction\n",
    "test_pred_scaled = model.predict(x_test).flatten()\n",
    "test_pred = scaler.inverse_transform(test_pred_scaled.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105d270e",
   "metadata": {},
   "source": [
    "## Evaluating The Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb54a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# align with actual\n",
    "y_train_al = data['Close'].iloc[SEQ_LEN:len(train)].values\n",
    "y_test_al = data['Close'].iloc[len(train) + SEQ_LEN:].values\n",
    "\n",
    "train_pred = train_pred[-len(y_train_al):]\n",
    "test_pred = test_pred[-len(y_test_al):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7977788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return MSE, MAE, RMSE, R2 and MAPE results as a list\n",
    "train_metrics = Evaluator.calculate_metrics(y_train_al, train_pred)\n",
    "test_metrics = Evaluator.calculate_metrics(y_test_al, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7ef8a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack metrics\n",
    "train_mse, train_mae, train_rmse, train_r2, train_mape = train_metrics\n",
    "test_mse, test_mae, test_rmse, test_r2, test_mape = test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1584a1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Performance Comparison: Train vs Test (LSTM) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Training</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>7.029</td>\n",
       "      <td>75.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAE</td>\n",
       "      <td>1.478</td>\n",
       "      <td>7.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>2.651</td>\n",
       "      <td>8.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R2 Score</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>2.503</td>\n",
       "      <td>4.117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Metric  Training    Test\n",
       "0       MSE     7.029  75.864\n",
       "1       MAE     1.478   7.595\n",
       "2      RMSE     2.651   8.710\n",
       "3  R2 Score     0.996   0.919\n",
       "4      MAPE     2.503   4.117"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  train vs test performance\n",
    "model_performance = Evaluator.print_evaluation_tables(\"LSTM\", train_metrics, test_metrics)\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d1351",
   "metadata": {},
   "source": [
    "# Cross-Validation, Summary and Overfitting Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390f8aa0",
   "metadata": {},
   "source": [
    "## Cross Validation with TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b60874b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeSeriesSplit CV on training set as diagnostic.\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(x_train), start=1):\n",
    "    x_tr, x_tst = x_train[train_idx], x_train[test_idx]\n",
    "    y_tr, y_tst = y_train[train_idx], y_train[test_idx]\n",
    "\n",
    "    pred = np.full_like(y_tst, y_tr[-1])\n",
    "    cv_metrics = Evaluator.calculate_metrics(y_tst, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b85820a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack metrics\n",
    "cv_mse, cv_mae, cv_rmse, cv_r2, cv_mape = cv_metrics\n",
    "\n",
    "# cross validation performance\n",
    "model_cv = pd.DataFrame({\n",
    "    'Model': ['LSTM'],\n",
    "    'CV_MSE': [cv_mse],\n",
    "    'CV_MAE': [cv_mae],\n",
    "    'CV_RMSE':[cv_rmse],\n",
    "    'CV_R2': [cv_r2],\n",
    "    'CV_MAPE': [cv_mape]\n",
    "}).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6429740f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Metrics (Training folds):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV_MSE</th>\n",
       "      <th>CV_MAE</th>\n",
       "      <th>CV_RMSE</th>\n",
       "      <th>CV_R2</th>\n",
       "      <th>CV_MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.086</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>12.897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  CV_MSE  CV_MAE  CV_RMSE  CV_R2  CV_MAPE\n",
       "0  LSTM   0.007    0.07    0.086 -0.191   12.897"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Cross-Validation Metrics (Training folds):\")\n",
    "model_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4cddd3",
   "metadata": {},
   "source": [
    "## Summary of the Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72c08b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_summary = pd.DataFrame({\n",
    "    'Metrics' : ['MSE', 'MAE', 'RMSE', 'R2-Score', 'MAPE'],\n",
    "    'Train': train_metrics,\n",
    "    'CV': cv_metrics,\n",
    "    'Test': test_metrics\n",
    "}).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54940512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Summary of The Model Evaluation ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>Train</th>\n",
       "      <th>CV</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>7.029</td>\n",
       "      <td>0.007</td>\n",
       "      <td>75.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAE</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>2.651</td>\n",
       "      <td>0.086</td>\n",
       "      <td>8.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R2-Score</td>\n",
       "      <td>0.996</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>2.503</td>\n",
       "      <td>12.897</td>\n",
       "      <td>4.117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Metrics  Train      CV    Test\n",
       "0       MSE  7.029   0.007  75.864\n",
       "1       MAE  1.478   0.070   7.595\n",
       "2      RMSE  2.651   0.086   8.710\n",
       "3  R2-Score  0.996  -0.191   0.919\n",
       "4      MAPE  2.503  12.897   4.117"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=== Summary of The Model Evaluation ===\")\n",
    "perf_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eabd6a",
   "metadata": {},
   "source": [
    "## Overfitting Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27948ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting analysis (compare CV_RMSE to Test_RMSE)\n",
    "overfit = {\n",
    "    'Model': 'LSTM',\n",
    "    'CV_RMSE': float(cv_rmse),\n",
    "    'Test_RMSE': float(test_rmse),\n",
    "    'RMSE_Increase': float(test_rmse - cv_rmse) if (not np.isnan(cv_rmse) and not np.isnan(test_rmse)) else np.nan,\n",
    "    'Overfitting_Ratio': float(test_rmse / (cv_rmse + 1e-8)) if not np.isnan(cv_rmse) else np.nan\n",
    "}\n",
    "\n",
    "overfit_df = pd.DataFrame([overfit]).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac65b9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Overfitting Analysis (LSTM Model) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV_RMSE</th>\n",
       "      <th>Test_RMSE</th>\n",
       "      <th>RMSE_Increase</th>\n",
       "      <th>Overfitting_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.086</td>\n",
       "      <td>8.71</td>\n",
       "      <td>8.624</td>\n",
       "      <td>101.567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  CV_RMSE  Test_RMSE  RMSE_Increase  Overfitting_Ratio\n",
       "0  LSTM    0.086       8.71          8.624            101.567"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=== Overfitting Analysis (LSTM Model) ===\")\n",
    "overfit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f286c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggrageted model performance\n",
    "agg_perf = pd.DataFrame({\n",
    "    'Model': ['LSTM'],\n",
    "    'Test MAE' : test_mae,\n",
    "    'Test R2-Score': test_r2,\n",
    "    'Test MAPE' : test_mape,\n",
    "    'CV MAE' : cv_mae,\n",
    "    'CV R2' : cv_r2,\n",
    "    'CV MAPE' : cv_mape,\n",
    "    'RMSE Increase' : overfit.get('RMSE_Increase', np.nan),\n",
    "    'Overfitting Ratio' : overfit.get('Overfitting_Ratio', np.nan)\n",
    "}).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76c28e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test R2-Score</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>CV MAE</th>\n",
       "      <th>CV R2</th>\n",
       "      <th>CV MAPE</th>\n",
       "      <th>RMSE Increase</th>\n",
       "      <th>Overfitting Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>7.595</td>\n",
       "      <td>0.919</td>\n",
       "      <td>4.117</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>12.897</td>\n",
       "      <td>8.624</td>\n",
       "      <td>101.567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Test MAE  Test R2-Score  Test MAPE  CV MAE  CV R2  CV MAPE  \\\n",
       "0  LSTM     7.595          0.919      4.117    0.07 -0.191   12.897   \n",
       "\n",
       "   RMSE Increase  Overfitting Ratio  \n",
       "0          8.624            101.567  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bba43ae",
   "metadata": {},
   "source": [
    "# Model Performance and Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96a4002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model persistor object\n",
    "persister = ModelPersister(model_name=\"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08da142f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to aggregated performance: ..\\artifacts\\model-performance\\a_ModelPerformance.csv\n"
     ]
    }
   ],
   "source": [
    "# aggregate model performance\n",
    "persister.aggregated_performance(agg_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12fc44ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM performance saved: ..\\artifacts\\model-performance\\lstmPerformance.csv\n"
     ]
    }
   ],
   "source": [
    "# save ariXGBoost model performance\n",
    "persister.save_performance(perf_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79e4b2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to overfitting analysis: ..\\artifacts\\model-performance\\a_overfittingAnalysis.csv\n"
     ]
    }
   ],
   "source": [
    "# save overfitting analysis\n",
    "persister.append_overfitting(overfit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c291647c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved: ..\\artifacts\\models/lstm.pkl\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "persister.save_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
