{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f8bf0e",
   "metadata": {},
   "source": [
    "# ARIMA Model Development With Auto Arima Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341509e4",
   "metadata": {},
   "source": [
    "# Import Libraries and Root Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da4b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Configure the utilities module path for imports \"\"\"\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# get project root as parent of current working directory\n",
    "project_root = Path(os.getcwd()).parent\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d1eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Import libraries to develop ARIMA model \"\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from src.utilities import StockDataProcessor, Evaluator, ModelPersister\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ada1b0",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057d728f",
   "metadata": {},
   "source": [
    "## Artifacts Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ca307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset from file\n",
    "file = Path(r'../data/AAPL_preprocessed.csv')\n",
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "615439b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, validation, and test sets\n",
    "train, test = StockDataProcessor.time_based_split(data)\n",
    "\n",
    "y_train = train['Close'].copy()\n",
    "y_test = test['Close'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0a957c",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c76ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and fit the auto_arima model\n",
    "model =  auto_arima(y_train.values,\n",
    "                    seasonal=False,\n",
    "                    stepwise=True,\n",
    "                    suppress_warnings=True,\n",
    "                    error_action='ignore',\n",
    "                    max_p=5,\n",
    "                    max_d=5,\n",
    "                    max_q=5,\n",
    "                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70beff58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>    0.0490</td> <td>    0.024</td> <td>    2.046</td> <td> 0.041</td> <td>    0.002</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ma.L1</th>     <td>   -0.0687</td> <td>    0.009</td> <td>   -7.695</td> <td> 0.000</td> <td>   -0.086</td> <td>   -0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sigma2</th>    <td>    1.7148</td> <td>    0.018</td> <td>   97.208</td> <td> 0.000</td> <td>    1.680</td> <td>    1.749</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lcccccc}\n",
       "\\toprule\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{intercept} &       0.0490  &        0.024     &     2.046  &         0.041        &        0.002    &        0.096     \\\\\n",
       "\\textbf{ma.L1}     &      -0.0687  &        0.009     &    -7.695  &         0.000        &       -0.086    &       -0.051     \\\\\n",
       "\\textbf{sigma2}    &       1.7148  &        0.018     &    97.208  &         0.000        &        1.680    &        1.749     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model summary (coefficients information)\n",
    "model.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3086f20",
   "metadata": {},
   "source": [
    "## Apply Model to Make Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a65527",
   "metadata": {},
   "source": [
    "### Make Prediction on Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8342671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-sample predictions: align predictions to actual training index safely\n",
    "try:\n",
    "    sample_pred = model.predict_in_sample()\n",
    "    sample_pred = np.asarray(sample_pred, dtype=float)\n",
    "\n",
    "except Exception as e:\n",
    "    # if predict_in_sample fails, fallback to fittedvalues if available, else NaNs\n",
    "    print(\"predict_in_sample() failed with:\", e)\n",
    "    \n",
    "    try:\n",
    "        sample_pred = model.arima_res_.fittedvalues  # may be available\n",
    "        sample_pred = np.asarray(sample_pred, dtype=float)\n",
    "    \n",
    "    except Exception:\n",
    "        sample_pred = np.full(len(y_train), np.nan, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e1da68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALIGNMENT: ensure we compare true and predicted with the same length and order\n",
    "if len(sample_pred) == len(y_train):\n",
    "    train_pred = y_train.values\n",
    "\n",
    "else:\n",
    "    # prefer tail-alignment: predict_in_sample often aligns to the end of fitted sample\n",
    "    train_pred = y_train.values[-len(sample_pred):]\n",
    "    print(f\"In-sample prediction length {len(sample_pred)} differs from train length {len(y_train)}; aligned on tail.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d9cef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on training (in-sample) using your Evaluator (truth first, preds second)\n",
    "train_metrics = Evaluator.calculate_metrics(train_pred, sample_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cca9a72",
   "metadata": {},
   "source": [
    "### Make Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = len(y_test)\n",
    "test_pred = model.predict(n_periods=n_test)\n",
    "test_pred = np.asarray(test_pred, dtype=float)\n",
    "\n",
    "# Align forecast to test index if test has index\n",
    "if isinstance(y_test, pd.Series) and y_test.index is not None:\n",
    "    test_pred_series = pd.Series(test_pred, index=y_test.index[:len(test_pred)])\n",
    "\n",
    "else:\n",
    "    test_pred_series = pd.Series(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test metrics evaluation\n",
    "test_metrics = Evaluator.calculate_metrics(y_test.values[:len(test_pred)], test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "991e1087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_actual</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137.987091</td>\n",
       "      <td>140.370557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138.144409</td>\n",
       "      <td>140.419509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141.349289</td>\n",
       "      <td>140.468461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147.110229</td>\n",
       "      <td>140.517413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146.323761</td>\n",
       "      <td>140.566365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>146.195969</td>\n",
       "      <td>140.615318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>148.653702</td>\n",
       "      <td>140.664270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>142.922241</td>\n",
       "      <td>140.713222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>143.669403</td>\n",
       "      <td>140.762174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>146.195969</td>\n",
       "      <td>140.811126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_actual      y_pred\n",
       "0  137.987091  140.370557\n",
       "1  138.144409  140.419509\n",
       "2  141.349289  140.468461\n",
       "3  147.110229  140.517413\n",
       "4  146.323761  140.566365\n",
       "5  146.195969  140.615318\n",
       "6  148.653702  140.664270\n",
       "7  142.922241  140.713222\n",
       "8  143.669403  140.762174\n",
       "9  146.195969  140.811126"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a table of actual vs pred\n",
    "comparison = pd.DataFrame({\n",
    "    'y_actual': y_test.values[:len(test_pred)],\n",
    "    'y_pred': test_pred\n",
    "})\n",
    "\n",
    "comparison.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afffdafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Performance Comparison: Train vs Test (ARIMA) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.772</td>\n",
       "      <td>1013.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.694</td>\n",
       "      <td>24.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.331</td>\n",
       "      <td>31.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.999</td>\n",
       "      <td>-0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>1.297</td>\n",
       "      <td>12.540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train      Test\n",
       "MSE   1.772  1013.019\n",
       "MAE   0.694    24.663\n",
       "RMSE  1.331    31.828\n",
       "R2    0.999    -0.071\n",
       "MAPE  1.297    12.540"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train vs Test Performance\n",
    "model_performance = Evaluator.print_evaluation_tables(\"ARIMA\", train_metrics, test_metrics)\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fc1683",
   "metadata": {},
   "source": [
    "## Time-Series Cross-Validation on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa299d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeSeriesSplit CV on training set as diagnostic.\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_metrics_list = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(y_train.values), start=1):\n",
    "    y_trn = y_train.values[train_idx]\n",
    "    y_test = y_train.values[val_idx]\n",
    "    \n",
    "    try:\n",
    "        cv_model = auto_arima(\n",
    "            y_trn,\n",
    "            seasonal=False,\n",
    "            stepwise=True,\n",
    "            suppress_warnings=True,\n",
    "            error_action='warn',\n",
    "            max_p=3, max_d=2, max_q=3,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        cv_pred = cv_model.predict(n_periods=len(y_test))\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Log the error and use persistence forecast as fallback, but keep running\n",
    "        print(f\"Fold {fold}: auto_arima failed with {e}; using persistence fallback.\")\n",
    "        cv_pred = np.full(shape=len(y_test), fill_value=float(y_trn[-1]), dtype=float)\n",
    "\n",
    "    metrics = Evaluator.calculate_metrics(y_test, cv_pred)\n",
    "    cv_metrics_list.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83f3b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate CV metrics (mean for each metric)\n",
    "cv_agg = {k: float(np.nanmean([m[k] for m in cv_metrics_list])) for k in cv_metrics_list[0].keys()}\n",
    "model_cv = pd.DataFrame(cv_agg, index=[\"ARIMA\"]).round(3)\n",
    "model_cv.columns = ['CV_MSE', 'CV_MAE', 'CV_RMSE', 'CV_R2', 'CV_MAPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78d3d7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Metrics (Training folds):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV_MSE</th>\n",
       "      <th>CV_MAE</th>\n",
       "      <th>CV_RMSE</th>\n",
       "      <th>CV_R2</th>\n",
       "      <th>CV_MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ARIMA</th>\n",
       "      <td>3911.595</td>\n",
       "      <td>32.545</td>\n",
       "      <td>37.569</td>\n",
       "      <td>-12.031</td>\n",
       "      <td>36.658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CV_MSE  CV_MAE  CV_RMSE   CV_R2  CV_MAPE\n",
       "ARIMA  3911.595  32.545   37.569 -12.031   36.658"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Cross-Validation Metrics (Training folds):\")\n",
    "model_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18d1574",
   "metadata": {},
   "source": [
    "## Summary of The Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ad62149",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_summary = pd.DataFrame({\n",
    "    'Train': train_metrics,\n",
    "    'CV': cv_agg,\n",
    "    'Test': test_metrics\n",
    "}).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8044c547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Summary of The Model Evaluation ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>CV</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.772</td>\n",
       "      <td>3911.595</td>\n",
       "      <td>1013.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.694</td>\n",
       "      <td>32.545</td>\n",
       "      <td>24.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.331</td>\n",
       "      <td>37.569</td>\n",
       "      <td>31.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.999</td>\n",
       "      <td>-12.031</td>\n",
       "      <td>-0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>1.297</td>\n",
       "      <td>36.658</td>\n",
       "      <td>12.540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train        CV      Test\n",
       "MSE   1.772  3911.595  1013.019\n",
       "MAE   0.694    32.545    24.663\n",
       "RMSE  1.331    37.569    31.828\n",
       "R2    0.999   -12.031    -0.071\n",
       "MAPE  1.297    36.658    12.540"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=== Summary of The Model Evaluation ===\")\n",
    "perf_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515ca35a",
   "metadata": {},
   "source": [
    "# Overfitting Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af7767ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting analysis (compare CV_RMSE to Test_RMSE)\n",
    "cv_rmse = cv_agg.get('RMSE', cv_agg.get('RMSE', np.nan))  # double fallback\n",
    "test_rmse = test_metrics.get('RMSE') if isinstance(test_metrics, dict) else (test_metrics['RMSE'] if hasattr(test_metrics,'__getitem__') else np.nan)\n",
    "\n",
    "overfit = {\n",
    "    'Model': 'ARIMA',\n",
    "    'CV_RMSE': float(cv_rmse),\n",
    "    'Test_RMSE': float(test_rmse),\n",
    "    'RMSE_Increase': float(test_rmse - cv_rmse) if (not np.isnan(cv_rmse) and not np.isnan(test_rmse)) else np.nan,\n",
    "    'Overfitting_Ratio': float(test_rmse / (cv_rmse + 1e-8)) if not np.isnan(cv_rmse) else np.nan\n",
    "}\n",
    "\n",
    "overfit_df = pd.DataFrame([overfit]).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f07a2858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Overfitting Analysis (ARIMA Model) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV_RMSE</th>\n",
       "      <th>Test_RMSE</th>\n",
       "      <th>RMSE_Increase</th>\n",
       "      <th>Overfitting_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARIMA</td>\n",
       "      <td>37.569</td>\n",
       "      <td>31.828</td>\n",
       "      <td>-5.741</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  CV_RMSE  Test_RMSE  RMSE_Increase  Overfitting_Ratio\n",
       "0  ARIMA   37.569     31.828         -5.741              0.847"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=== Overfitting Analysis (ARIMA Model) ===\")\n",
    "overfit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b99040",
   "metadata": {},
   "source": [
    "# Model Performance and Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c41e653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattening datarames for persisting\n",
    "model_cv_flat = {k: list(v.values())[0] for k, v in model_cv.to_dict().items()}\n",
    "overfit_df_flat = {k: list(v.values())[0] for k, v in overfit_df.to_dict().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "812a6baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_perf = {'Model': 'ARIMA', **model_cv_flat, **test_metrics}\n",
    "overfit_perf = {'Model': 'ARIMA', **overfit_df_flat}\n",
    "\n",
    "# model persistor object\n",
    "persister = ModelPersister(model_name=\"Arima\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aadaf5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to aggregated performance: ..\\artifacts\\model-performance\\a_ModelPerformance.csv\n"
     ]
    }
   ],
   "source": [
    "# aggregate model performance\n",
    "persister.aggregated_performance(model_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc88a998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arima performance saved: ..\\artifacts\\model-performance\\arimaPerformance.csv\n"
     ]
    }
   ],
   "source": [
    "# save ariXGBoost model performance\n",
    "persister.save_performance(perf_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b1816f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to overfitting analysis: ..\\artifacts\\model-performance\\a_overfittingAnalysis.csv\n"
     ]
    }
   ],
   "source": [
    "# save overfitting analysis\n",
    "persister.append_overfitting(overfit_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bce60f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved: ..\\artifacts\\models/arima.pkl\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "persister.save_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
